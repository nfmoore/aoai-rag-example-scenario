{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom RAG Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.utilities import OrchestrationClient\n",
    "\n",
    "# Create orchestration client\n",
    "orchestration_client = OrchestrationClient(\n",
    "    open_ai_endpoint=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "    open_ai_chat_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "    open_ai_embedding_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    search_endpoint=os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "    search_index_name=os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate chat response from initial user query\n",
    "chat_history = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Which tent is the most waterproof?\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "chat_history = orchestration_client.generate_chat_response(chat_history)\n",
    "print(chat_history[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate chat response from follow-up user query\n",
    "chat_history[\"messages\"].append(\n",
    "    {\"role\": \"user\", \"content\": \"Tell me more about the Alpine Explorer Tent?\"}\n",
    ")\n",
    "\n",
    "chat_history = orchestration_client.generate_chat_response(chat_history)\n",
    "print(chat_history[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI Service REST API\n",
    "\n",
    "Note: this will require public access on Azure AI Search or a Microsft managed private endpoint for private access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "open_ai_endpoint = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "open_ai_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "open_ai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "chat_endpoint = f\"{open_ai_endpoint}/openai/deployments/{open_ai_chat_deployment}/extensions/chat/completions?api-version={open_ai_api_version}\"\n",
    "\n",
    "request_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token.token}\",\n",
    "}\n",
    "\n",
    "request_payload = {\n",
    "    \"dataSources\": [\n",
    "        {\n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "                \"indexName\": os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\"),\n",
    "                \"queryType\": \"vectorSemanticHybrid\",\n",
    "                \"embeddingDeploymentName\": os.getenv(\n",
    "                    \"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"\n",
    "                ),\n",
    "                \"fieldsMapping\": {\"titleField\": \"title\", \"urlField\": \"path\"},\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Which tent is the most waterproof?\"}],\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    chat_endpoint,\n",
    "    headers=request_headers,\n",
    "    json=request_payload,\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Based on the information provided, both the Alpine Explorer Tent and the TrailMaster X4 Tent are waterproof. The Alpine Explorer Tent has a rainfly with a waterproof rating of 3000mm [product_info_8.md], while the TrailMaster X4 Tent has a rainfly with a waterproof rating of 2000mm [product_info_1.md]. Therefore, both tents offer reliable protection against rain and moisture.\"\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = (\n",
    "    \"This document refers to [product_info_1.md] and [another_file.md]. More text here.\"\n",
    ")\n",
    "\n",
    "def replace_references(text: str) -> str:\n",
    "    # Regex to match references in the format [*.md]\n",
    "    regex = r\"\\[([^\\]]*.md)\\]\"\n",
    "\n",
    "    # Replace matched references with modified references (appending \":blue\")\n",
    "    modified_text = re.sub(regex, r\"*:blue[\\1]*\", text)\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "# Regex to match references in the format [*.md]\n",
    "regex = r\"\\[([^\\]]*.md)\\]\"\n",
    "\n",
    "# Replace matched references with modified references (appending \":blue\")\n",
    "modified_text = re.sub(regex, r\"*:blue[\\1]*\", text)\n",
    "\n",
    "print(modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
