{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Queries with Knowledge Base Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Custom Client\n",
    "\n",
    "This approach will use the `RetrievalAugmentedGenerationClient` class defined in `src/rag/utilities.py`. This will NOT require a Microsoft managed private endpoint for private access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.utilities import RetrievalAugmentedGenerationClient\n",
    "\n",
    "# Create orchestration client\n",
    "rag_client = RetrievalAugmentedGenerationClient(\n",
    "    open_ai_endpoint=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "    open_ai_chat_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "    open_ai_embedding_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    search_endpoint=os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "    search_index_name=os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\"),\n",
    "    system_prompt_configuration_file=\"../src/rag/configuration.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = []\n",
    "message_history = rag_client.get_answer(\"Which tent is the most waterproof?\", message_history=message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in message_history:\n",
    "    content = message['content'].split(\"Sources:\")[0].strip()\n",
    "    print(f\"{message['role'].title()}: {content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = rag_client.get_answer(\"Tell me more about the Alpine Explorer Tent?\", message_history=message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in message_history:\n",
    "    content = message['content'].split(\"Sources:\")[0].strip()\n",
    "    print(f\"{message['role'].title()}: {content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Azure OpenAI Service REST API\n",
    "\n",
    "This will require public access on Azure AI Search or a Microsoft managed private endpoint for private access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "open_ai_endpoint = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "open_ai_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "open_ai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "chat_endpoint = f\"{open_ai_endpoint}/openai/deployments/{open_ai_chat_deployment}/extensions/chat/completions?api-version={open_ai_api_version}\"\n",
    "\n",
    "request_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token.token}\",\n",
    "}\n",
    "\n",
    "request_payload = {\n",
    "    \"dataSources\": [\n",
    "        {\n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"),\n",
    "                \"indexName\": os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\"),\n",
    "                \"queryType\": \"vectorSemanticHybrid\",\n",
    "                \"embeddingDeploymentName\": os.getenv(\n",
    "                    \"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"\n",
    "                ),\n",
    "                \"fieldsMapping\": {\"titleField\": \"title\", \"urlField\": \"path\"},\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Which tent is the most waterproof?\"}],\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    chat_endpoint,\n",
    "    headers=request_headers,\n",
    "    json=request_payload,\n",
    ")\n",
    "\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
